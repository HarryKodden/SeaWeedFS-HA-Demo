{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ee9afa0",
   "metadata": {},
   "source": [
    "# SeaweedFS High Availability and Resilience Testing\n",
    "\n",
    "This notebook demonstrates SeaweedFS's active-active resilience capabilities by simulating failures and observing how the system heals itself. We'll use the high availability setup defined in `docker-compose.yml` with multiple masters, volumes, and filers.\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "The high availability cluster consists of:\n",
    "- 3 master servers in a Raft cluster\n",
    "- 3 volume servers across different racks\n",
    "- 2 filer servers\n",
    "- NGINX load balancer for the filer service\n",
    "\n",
    "### Network Architecture\n",
    "\n",
    "All components are connected to an internal Docker network, while only the NGINX container is exposed to the external network. This enhances security by limiting the attack surface.\n",
    "\n",
    "Access to all components is provided through the NGINX container using path-based routing:\n",
    "\n",
    "- **Filer Access**: `http://seaweed-ha-cluster.${DOMAIN}/` (Root path)\n",
    "- **S3 API**: `http://seaweed-ha-cluster.${DOMAIN}/s3/`\n",
    "- **Master Servers**: \n",
    "  - `http://seaweed-ha-cluster.${DOMAIN}/master/1/`\n",
    "  - `http://seaweed-ha-cluster.${DOMAIN}/master/2/`\n",
    "  - `http://seaweed-ha-cluster.${DOMAIN}/master/3/`\n",
    "- **Volume Servers**:\n",
    "  - `http://seaweed-ha-cluster.${DOMAIN}/volume/1/`\n",
    "  - `http://seaweed-ha-cluster.${DOMAIN}/volume/2/`\n",
    "  - `http://seaweed-ha-cluster.${DOMAIN}/volume/3/`\n",
    "\n",
    "This setup provides redundancy at all levels and enables us to test resilience against various types of failures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdec546e",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a3ecbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import botocore\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import requests\n",
    "from IPython.display import display, Markdown, HTML\n",
    "import re\n",
    "\n",
    "def create_s3_client():\n",
    "    \"\"\"Create S3 client with configuration for local SeaweedFS server\n",
    "    \n",
    "    This function creates a boto3 S3 client configured to connect to the SeaweedFS S3 API.\n",
    "    It uses environment variables or default values for endpoint and credentials.\n",
    "    \"\"\"\n",
    "    # Get environment variables with defaults\n",
    "    s3_endpoint = os.getenv('S3_ENDPOINT', 'http://localhost:9333')\n",
    "    aws_access_key = os.getenv('AWS_ACCESS_KEY_ID', 'IVYE1A87YT828DTI1I0B157E2JAGV0HQ')\n",
    "    aws_secret_key = os.getenv('AWS_SECRET_ACCESS_KEY', '5MfEKDj6jGEOB5AGozVoLhgqC1VpMxlDnJV2F8yO')\n",
    "    \n",
    "    print(f\"Using S3 endpoint: {s3_endpoint}\")\n",
    "    \n",
    "    # Configure boto3 client with explicit signature version\n",
    "    s3_config = botocore.config.Config(\n",
    "        signature_version='s3v4',  # Explicitly use S3v4 signatures\n",
    "        connect_timeout=5,\n",
    "        retries={'max_attempts': 0}\n",
    "    )\n",
    "    \n",
    "    # Create S3 client\n",
    "    s3_client = boto3.client(\n",
    "        's3',\n",
    "        endpoint_url=s3_endpoint,\n",
    "        aws_access_key_id=aws_access_key,\n",
    "        aws_secret_access_key=aws_secret_key,\n",
    "        config=s3_config\n",
    "    )\n",
    "    \n",
    "    return s3_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b17b412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables set:\n",
      "S3_ENDPOINT: http://localhost:9333\n",
      "AWS_ACCESS_KEY_ID: IVYE1A87YT828DTI1I0B157E2JAGV0HQ\n",
      "AWS_SECRET_ACCESS_KEY: 5MfE...F8yO\n"
     ]
    }
   ],
   "source": [
    "# Set environment variables explicitly\n",
    "import os\n",
    "\n",
    "# Set the S3 endpoint URL to the non-path based endpoint\n",
    "os.environ['S3_ENDPOINT'] = 'http://localhost:9333'\n",
    "os.environ['SEAWEED_S3_URL'] = 'http://localhost:9333'\n",
    "\n",
    "# Set the AWS credentials from the filer container\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'IVYE1A87YT828DTI1I0B157E2JAGV0HQ'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = '5MfEKDj6jGEOB5AGozVoLhgqC1VpMxlDnJV2F8yO'\n",
    "\n",
    "print(\"Environment variables set:\")\n",
    "print(f\"S3_ENDPOINT: {os.environ['S3_ENDPOINT']}\")\n",
    "print(f\"AWS_ACCESS_KEY_ID: {os.environ['AWS_ACCESS_KEY_ID']}\")\n",
    "print(f\"AWS_SECRET_ACCESS_KEY: {os.environ['AWS_SECRET_ACCESS_KEY'][:4]}...{os.environ['AWS_SECRET_ACCESS_KEY'][-4:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277e1d20",
   "metadata": {},
   "source": [
    "## 2. Setup Helper Functions\n",
    "\n",
    "Let's create some utility functions to help us interact with the SeaweedFS cluster and monitor its state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9be336",
   "metadata": {},
   "source": [
    "### Secure Network Architecture\n",
    "\n",
    "In our setup, we've implemented a secure network architecture by:\n",
    "\n",
    "1. **Internal Network Isolation**: \n",
    "   - All SeaweedFS components (masters, volumes, filers) are only connected to the internal network\n",
    "   - No direct port exposure from these services to the host machine\n",
    "\n",
    "2. **Single External Access Point**:\n",
    "   - Only the NGINX container is connected to both internal and external networks\n",
    "   - NGINX serves as the secure gateway to all SeaweedFS services\n",
    "\n",
    "3. **Path-Based Routing**:\n",
    "   - NGINX routes requests to the appropriate service based on the URL path\n",
    "   - This allows controlled access to internal components while maintaining security\n",
    "\n",
    "4. **Basic Authentication for Cluster Administration**:\n",
    "   - All master and volume server paths (`/master/*` and `/volume/*`) are protected with HTTP Basic Authentication\n",
    "   - Only authorized administrators can access these management interfaces\n",
    "   - Authentication credentials are stored in a .htpasswd file mounted to the NGINX container\n",
    "   - Regular users can still access the filer and S3 endpoints without authentication\n",
    "\n",
    "This approach follows best practices for container security by minimizing the attack surface and providing a single, well-controlled entry point to the system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b997eed",
   "metadata": {},
   "source": [
    "### Setting Up Basic Authentication\n",
    "\n",
    "Before starting the cluster, you need to create a `.htpasswd` file for NGINX basic authentication. We've provided a script to help with this:\n",
    "\n",
    "```bash\n",
    "# Create the .htpasswd file with a username and password\n",
    "./create_htpasswd.sh admin your_secure_password\n",
    "```\n",
    "\n",
    "This creates a `.htpasswd` file in the current directory, which will be mounted to the NGINX container when the cluster starts. The basic authentication will apply only to the cluster management paths (`/master/` and `/volume/`), leaving the regular filer and S3 access unaffected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246502ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_command(command):\n",
    "    \"\"\"Run a shell command and return the output\"\"\"\n",
    "    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "    if result.returncode != 0:\n",
    "        print(f\"Error executing command: {command}\")\n",
    "        print(f\"Error: {result.stderr}\")\n",
    "    return result.stdout.strip()\n",
    "\n",
    "def get_admin_auth():\n",
    "    \"\"\"Get the admin username and password for cluster administration\"\"\"\n",
    "    # You can hardcode credentials here for testing purposes\n",
    "    # In production, you should use environment variables or a secure storage method\n",
    "    admin_user = os.getenv(\"SEAWEED_ADMIN_USER\", \"admin\")\n",
    "    admin_pass = os.getenv(\"SEAWEED_ADMIN_PASSWORD\", \"admin\")\n",
    "    return (admin_user, admin_pass)\n",
    "\n",
    "def get_cluster_status():\n",
    "    \"\"\"Get the status of the SeaweedFS cluster from all master servers\"\"\"\n",
    "    statuses = {}\n",
    "    # Access via NGINX with path-based routing\n",
    "    nginx_base_url = \"http://localhost:9080\"  # Port matches docker-compose.yml mapping\n",
    "    auth = get_admin_auth()\n",
    "    \n",
    "    for i in range(1, 4):  # Three master servers\n",
    "        try:\n",
    "            response = requests.get(\n",
    "                f\"{nginx_base_url}/master/{i}/cluster/status\", \n",
    "                timeout=2,\n",
    "                auth=auth  # Using basic auth\n",
    "            )\n",
    "            if response.status_code == 200:\n",
    "                statuses[f\"master{i}\"] = response.json()\n",
    "            else:\n",
    "                statuses[f\"master{i}\"] = {\"error\": f\"Status code: {response.status_code}\"}\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            statuses[f\"master{i}\"] = {\"error\": str(e)}\n",
    "    return statuses\n",
    "\n",
    "def get_volume_status():\n",
    "    \"\"\"Get the status of all volume servers\"\"\"\n",
    "    statuses = {}\n",
    "    # Access via NGINX with path-based routing\n",
    "    nginx_base_url = \"http://localhost:9080\"  # Port matches docker-compose.yml mapping\n",
    "    auth = get_admin_auth()\n",
    "    \n",
    "    for i in range(1, 4):  # Three volume servers\n",
    "        try:\n",
    "            response = requests.get(\n",
    "                f\"{nginx_base_url}/volume/{i}/status\", \n",
    "                timeout=2,\n",
    "                auth=auth  # Using basic auth\n",
    "            )\n",
    "            if response.status_code == 200:\n",
    "                statuses[f\"volume{i}\"] = response.json()\n",
    "            else:\n",
    "                statuses[f\"volume{i}\"] = {\"error\": f\"Status code: {response.status_code}\"}\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            statuses[f\"volume{i}\"] = {\"error\": str(e)}\n",
    "    return statuses\n",
    "\n",
    "def get_topology():\n",
    "    \"\"\"Get the topology of the SeaweedFS cluster\"\"\"\n",
    "    try:\n",
    "        # Access via NGINX with path-based routing\n",
    "        nginx_base_url = \"http://localhost:9080\"  # Port matches docker-compose.yml mapping\n",
    "        auth = get_admin_auth()\n",
    "        \n",
    "        # Try the first master, if it fails, try the others\n",
    "        for i in range(1, 4):\n",
    "            try:\n",
    "                response = requests.get(\n",
    "                    f\"{nginx_base_url}/master/{i}/dir/status\", \n",
    "                    timeout=2,\n",
    "                    auth=auth  # Using basic auth\n",
    "                )\n",
    "                if response.status_code == 200:\n",
    "                    return response.json()\n",
    "            except:\n",
    "                continue\n",
    "        return {\"error\": \"Could not get topology from any master\"}\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "def create_s3_client(use_nginx=True):\n",
    "    \"\"\"Create an S3 client configured to connect to SeaweedFS S3 API\"\"\"\n",
    "    # Get the AWS credentials from the .env file - these must match what's used by the filer service\n",
    "    aws_access_key_id = os.getenv('AWS_ACCESS_KEY_ID', 'seaweedfs')\n",
    "    aws_secret_access_key = os.getenv('AWS_SECRET_ACCESS_KEY', 'seaweedfs')\n",
    "    \n",
    "    # Check if we need to override with the default values used in docker-compose.yml\n",
    "    # This is important when the credentials in the .env file don't match what's in docker-compose.yml\n",
    "    docker_compose_default = 'seaweedfs'\n",
    "    if aws_access_key_id != docker_compose_default:\n",
    "        print(f\"Using AWS access key from .env: {aws_access_key_id[:4]}...{aws_access_key_id[-4:]}\")\n",
    "        print(\"If you get signature errors, try using 'seaweedfs' for both access and secret keys\")\n",
    "    \n",
    "    # Always use NGINX since direct access is no longer available\n",
    "    # The port must match the exposed port in docker-compose.yml\n",
    "    endpoint_url = \"http://localhost:9080/s3\"\n",
    "    \n",
    "    # For production with the domain name, you would use:\n",
    "    # endpoint_url = f\"https://seaweed-ha-cluster.{os.getenv('DOMAIN')}/s3\"\n",
    "    \n",
    "    s3_client = boto3.client(\n",
    "        's3',\n",
    "        endpoint_url=endpoint_url,\n",
    "        aws_access_key_id=aws_access_key_id,\n",
    "        aws_secret_access_key=aws_secret_access_key,\n",
    "        region_name='us-east-1',  # Default region\n",
    "        verify=False,  # Skip SSL verification for local development\n",
    "        config=boto3.session.Config(signature_version='s3v4')  # Explicitly use signature v4\n",
    "    )\n",
    "    return s3_client\n",
    "\n",
    "def format_table(data, title=None):\n",
    "    \"\"\"Format data as a styled HTML table\"\"\"\n",
    "    # Convert to DataFrame for easy formatting\n",
    "    if isinstance(data, list) and len(data) > 0 and isinstance(data[0], dict):\n",
    "        df = pd.DataFrame(data)\n",
    "    elif isinstance(data, dict):\n",
    "        df = pd.DataFrame([data])\n",
    "    else:\n",
    "        df = pd.DataFrame(data)\n",
    "    \n",
    "    try:\n",
    "        # Try to use DataFrame styling\n",
    "        styled_df = df.style\n",
    "        if title:\n",
    "            styled_df = styled_df.set_caption(title)\n",
    "        styled_df = styled_df.set_properties(**{\n",
    "            'text-align': 'left',\n",
    "            'border': '1px solid #ddd',\n",
    "            'padding': '8px',\n",
    "            'background-color': '#f5f5f5'\n",
    "        })\n",
    "        return styled_df\n",
    "    except AttributeError:\n",
    "        # Fallback to basic HTML if styling is not available\n",
    "        html = df.to_html(index=False)\n",
    "        if title:\n",
    "            html = f\"<h4>{title}</h4>\" + html\n",
    "        return HTML(html)\n",
    "\n",
    "def stop_container(container_name):\n",
    "    \"\"\"Stop a specific container in the HA setup\"\"\"\n",
    "    cmd = f\"docker stop demo-{container_name}-1\"\n",
    "    result = run_command(cmd)\n",
    "    print(f\"Stopped container: {container_name}\")\n",
    "    return result\n",
    "\n",
    "def start_container(container_name):\n",
    "    \"\"\"Start a specific container in the HA setup\"\"\"\n",
    "    cmd = f\"docker start demo-{container_name}-1\"\n",
    "    result = run_command(cmd)\n",
    "    print(f\"Started container: {container_name}\")\n",
    "    return result\n",
    "\n",
    "def check_containers():\n",
    "    \"\"\"Check the status of all containers in the HA setup\"\"\"\n",
    "    cmd = \"docker ps --format 'table {{.Names}}\\t{{.Status}}\\t{{.Ports}}' | grep demo\"\n",
    "    result = run_command(cmd)\n",
    "    print(\"Container Status:\")\n",
    "    print(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c93cd2e",
   "metadata": {},
   "source": [
    "## 3. Start the High Availability Cluster\n",
    "\n",
    "First, let's start the HA cluster using docker-compose.yml if it's not already running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a49b268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HA cluster is already running\n",
      "Container Status:\n",
      "demo-nginx-1                                         Up About a minute             0.0.0.0:9080->80/tcp, [::]:9080->80/tcp\n",
      "demo-filer1-1                                        Up About a minute (healthy)   7333/tcp, 8080/tcp, 8333/tcp, 8888/tcp, 9333/tcp, 18080/tcp, 18888/tcp, 19333/tcp\n",
      "demo-filer2-1                                        Up About a minute (healthy)   7333/tcp, 8080/tcp, 8333/tcp, 8888/tcp, 9333/tcp, 18080/tcp, 18888/tcp, 19333/tcp\n",
      "demo-volume2-1                                       Up About a minute (healthy)   7333/tcp, 8080/tcp, 8333/tcp, 8888/tcp, 9333/tcp, 18080/tcp, 18888/tcp, 19333/tcp\n",
      "demo-volume1-1                                       Up About a minute (healthy)   7333/tcp, 8080/tcp, 8333/tcp, 8888/tcp, 9333/tcp, 18080/tcp, 18888/tcp, 19333/tcp\n",
      "demo-volume3-1                                       Up About a minute (healthy)   7333/tcp, 8080/tcp, 8333/tcp, 8888/tcp, 9333/tcp, 18080/tcp, 18888/tcp, 19333/tcp\n",
      "demo-master1-1                                       Up About a minute (healthy)   7333/tcp, 8080/tcp, 8333/tcp, 8888/tcp, 9333/tcp, 18080/tcp, 18888/tcp, 19333/tcp\n",
      "demo-master3-1                                       Up About a minute (healthy)   7333/tcp, 8080/tcp, 8333/tcp, 8888/tcp, 9333/tcp, 18080/tcp, 18888/tcp, 19333/tcp\n",
      "demo-master2-1                                       Up About a minute (healthy)   7333/tcp, 8080/tcp, 8333/tcp, 8888/tcp, 9333/tcp, 18080/tcp, 18888/tcp, 19333/tcp\n",
      "token-exchange-demo-streamlit-app-1                  Up 6 days (healthy)           8501/tcp\n",
      "docker-demo1-1                                       Up 7 days (healthy)           22/tcp, 80-83/tcp, 389/tcp, 443/tcp, 636/tcp, 8080-8082/tcp\n"
     ]
    }
   ],
   "source": [
    "def start_ha_cluster():\n",
    "    \"\"\"Start the HA cluster using docker-compose.yml\"\"\"\n",
    "    print(\"Starting HA cluster...\")\n",
    "    cmd = \"docker compose up -d\"  # Using newer 'docker compose' format without hyphen\n",
    "    result = run_command(cmd)\n",
    "    print(\"HA cluster started. Waiting for services to initialize...\")\n",
    "    time.sleep(20)  # Give some time for services to initialize\n",
    "    return result\n",
    "\n",
    "def stop_ha_cluster():\n",
    "    \"\"\"Stop the HA cluster\"\"\"\n",
    "    print(\"Stopping HA cluster...\")\n",
    "    cmd = \"docker compose down\"  # Using newer 'docker compose' format without hyphen\n",
    "    result = run_command(cmd)\n",
    "    print(\"HA cluster stopped\")\n",
    "    return result\n",
    "\n",
    "# Check if the cluster is already running\n",
    "cluster_check = run_command(\"docker ps --format '{{.Names}}' | grep demo\")\n",
    "if not cluster_check or 'demo-master' not in cluster_check:\n",
    "    start_ha_cluster()\n",
    "else:\n",
    "    print(\"HA cluster is already running\")\n",
    "    check_containers()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f6e9c3",
   "metadata": {},
   "source": [
    "## 4. Check Initial Cluster Status\n",
    "\n",
    "Let's check the status of the cluster before we start our experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afceeb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not determine cluster leader\n",
      "\n",
      "S3 API (via NGINX): Error - expected string or bytes-like object\n",
      "S3 API (direct to filer1): Error - expected string or bytes-like object\n",
      "\n",
      "Container Status:\n",
      "Container Status:\n",
      "demo-nginx-1                                         Up 48 minutes             0.0.0.0:9080->80/tcp, [::]:9080->80/tcp\n",
      "demo-filer1-1                                        Up 48 minutes (healthy)   7333/tcp, 8080/tcp, 8333/tcp, 8888/tcp, 9333/tcp, 18080/tcp, 18888/tcp, 19333/tcp\n",
      "demo-filer2-1                                        Up 48 minutes (healthy)   7333/tcp, 8080/tcp, 8333/tcp, 8888/tcp, 9333/tcp, 18080/tcp, 18888/tcp, 19333/tcp\n",
      "demo-volume2-1                                       Up 48 minutes (healthy)   7333/tcp, 8080/tcp, 8333/tcp, 8888/tcp, 9333/tcp, 18080/tcp, 18888/tcp, 19333/tcp\n",
      "demo-volume1-1                                       Up 48 minutes (healthy)   7333/tcp, 8080/tcp, 8333/tcp, 8888/tcp, 9333/tcp, 18080/tcp, 18888/tcp, 19333/tcp\n",
      "demo-volume3-1                                       Up 48 minutes (healthy)   7333/tcp, 8080/tcp, 8333/tcp, 8888/tcp, 9333/tcp, 18080/tcp, 18888/tcp, 19333/tcp\n",
      "demo-master1-1                                       Up 48 minutes (healthy)   7333/tcp, 8080/tcp, 8333/tcp, 8888/tcp, 9333/tcp, 18080/tcp, 18888/tcp, 19333/tcp\n",
      "demo-master3-1                                       Up 48 minutes (healthy)   7333/tcp, 8080/tcp, 8333/tcp, 8888/tcp, 9333/tcp, 18080/tcp, 18888/tcp, 19333/tcp\n",
      "demo-master2-1                                       Up 48 minutes (healthy)   7333/tcp, 8080/tcp, 8333/tcp, 8888/tcp, 9333/tcp, 18080/tcp, 18888/tcp, 19333/tcp\n",
      "token-exchange-demo-streamlit-app-1                  Up 6 days (healthy)       8501/tcp\n",
      "docker-demo1-1                                       Up 8 days (healthy)       22/tcp, 80-83/tcp, 389/tcp, 443/tcp, 636/tcp, 8080-8082/tcp\n"
     ]
    }
   ],
   "source": [
    "def display_cluster_info():\n",
    "    \"\"\"Display comprehensive cluster information\"\"\"\n",
    "    # Get master leader information\n",
    "    leader_info = None\n",
    "    for i in range(1, 4):\n",
    "        try:\n",
    "            port = 9332 + i\n",
    "            response = requests.get(f\"http://localhost:{port}/cluster/status\", timeout=2)\n",
    "            if response.status_code == 200 and \"Leader\" in response.json():\n",
    "                leader_info = response.json()[\"Leader\"]\n",
    "                break\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    if leader_info:\n",
    "        print(f\"Cluster Leader: {leader_info}\")\n",
    "    else:\n",
    "        print(\"Could not determine cluster leader\")\n",
    "    \n",
    "    # Get cluster topology\n",
    "    topology = get_topology()\n",
    "    if \"error\" not in topology:\n",
    "        print(f\"\\nCluster Topology:\")\n",
    "        print(f\"  Data Centers: {len(topology.get('DataCenters', []))}\")\n",
    "        \n",
    "        # Count volumes by rack\n",
    "        volumes_by_rack = {}\n",
    "        volume_count = 0\n",
    "        for dc in topology.get('DataCenters', []):\n",
    "            for rack in dc.get('Racks', []):\n",
    "                rack_name = rack.get('Id', 'unknown')\n",
    "                rack_volumes = 0\n",
    "                for datanode in rack.get('DataNodes', []):\n",
    "                    rack_volumes += len(datanode.get('Volumes', []))\n",
    "                    volume_count += len(datanode.get('Volumes', []))\n",
    "                volumes_by_rack[rack_name] = rack_volumes\n",
    "                \n",
    "        print(f\"  Total Volumes: {volume_count}\")\n",
    "        print(\"  Volumes by Rack:\")\n",
    "        for rack, count in volumes_by_rack.items():\n",
    "            print(f\"    - {rack}: {count} volumes\")\n",
    "            \n",
    "    # Check S3 service\n",
    "    try:\n",
    "        s3_client = create_s3_client()\n",
    "        buckets = s3_client.list_buckets()\n",
    "        print(f\"\\nS3 API (via NGINX): Working\")\n",
    "        print(f\"  Buckets: {len(buckets.get('Buckets', []))}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nS3 API (via NGINX): Error - {str(e)}\")\n",
    "        \n",
    "    try:\n",
    "        s3_client = create_s3_client(use_nginx=False)\n",
    "        buckets = s3_client.list_buckets()\n",
    "        print(f\"S3 API (direct to filer1): Working\")\n",
    "        print(f\"  Buckets: {len(buckets.get('Buckets', []))}\")\n",
    "    except Exception as e:\n",
    "        print(f\"S3 API (direct to filer1): Error - {str(e)}\")\n",
    "    \n",
    "    # Display container status\n",
    "    print(\"\\nContainer Status:\")\n",
    "    check_containers()\n",
    "\n",
    "# Display initial cluster information\n",
    "display_cluster_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9481ad",
   "metadata": {},
   "source": [
    "## 5. Data Operations - Creating Test Data\n",
    "\n",
    "Let's create some test buckets and files to use in our resilience tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f52ae137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using S3 credentials:\n",
      "- Access Key: IVYE1A87YT828DTI1I0B157E2JAGV0HQ\n",
      "- Secret Key: 5MfE...F8yO\n",
      "Using S3 endpoint: http://localhost:9333\n",
      "Bucket doesn't exist yet: An error occurred (403) when calling the HeadBucket operation: Forbidden\n",
      "Creating bucket 'ha-test-bucket'...\n",
      "Error creating test bucket: An error occurred (SignatureDoesNotMatch) when calling the CreateBucket operation: The request signature we calculated does not match the signature you provided. Check your key and signing method.\n",
      "\n",
      "Possible solutions:\n",
      "1. Make sure the AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY in your .env file match\n",
      "   the values used by the filer services in docker-compose.yml\n",
      "2. Try using the default values by setting both to 'seaweedfs' in your .env file\n",
      "3. Check if the S3 port (9080) is correctly mapped in docker-compose.yml\n"
     ]
    }
   ],
   "source": [
    "def create_test_bucket(bucket_name=\"ha-test-bucket\"):\n",
    "    \"\"\"Create a test bucket\"\"\"\n",
    "    try:\n",
    "        # Check the AWS credentials we're using\n",
    "        aws_access_key = os.getenv('AWS_ACCESS_KEY_ID', 'seaweedfs')\n",
    "        aws_secret_key = os.getenv('AWS_SECRET_ACCESS_KEY', 'seaweedfs')\n",
    "        print(f\"Using S3 credentials:\")\n",
    "        print(f\"- Access Key: {aws_access_key}\")\n",
    "        print(f\"- Secret Key: {aws_secret_key[:4]}...{aws_secret_key[-4:] if len(aws_secret_key) > 8 else '****'}\")\n",
    "        \n",
    "        # Create the S3 client\n",
    "        s3_client = create_s3_client()\n",
    "        \n",
    "        # Check if bucket exists\n",
    "        try:\n",
    "            s3_client.head_bucket(Bucket=bucket_name)\n",
    "            print(f\"Bucket '{bucket_name}' already exists\")\n",
    "        except Exception as e:\n",
    "            print(f\"Bucket doesn't exist yet: {str(e)}\")\n",
    "            # Create the bucket\n",
    "            print(f\"Creating bucket '{bucket_name}'...\")\n",
    "            s3_client.create_bucket(Bucket=bucket_name)\n",
    "            print(f\"Created bucket '{bucket_name}'\")\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating test bucket: {e}\")\n",
    "        print(\"\\nPossible solutions:\")\n",
    "        print(\"1. Make sure the AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY in your .env file match\")\n",
    "        print(\"   the values used by the filer services in docker-compose.yml\")\n",
    "        print(\"2. Try using the default values by setting both to 'seaweedfs' in your .env file\")\n",
    "        print(\"3. Check if the S3 port (9080) is correctly mapped in docker-compose.yml\")\n",
    "        return False\n",
    "\n",
    "def upload_test_files(bucket_name=\"ha-test-bucket\", count=10, size_kb=100):\n",
    "    \"\"\"Upload test files to the bucket\"\"\"\n",
    "    try:\n",
    "        s3_client = create_s3_client()\n",
    "        \n",
    "        # Create random data\n",
    "        data = bytes(np.random.bytes(size_kb * 1024))\n",
    "        \n",
    "        # Upload files\n",
    "        for i in range(1, count + 1):\n",
    "            key = f\"test-file-{i}.dat\"\n",
    "            s3_client.put_object(Bucket=bucket_name, Key=key, Body=data)\n",
    "            print(f\"Uploaded {key} ({size_kb} KB)\")\n",
    "        \n",
    "        # List files to confirm\n",
    "        response = s3_client.list_objects_v2(Bucket=bucket_name)\n",
    "        files = response.get('Contents', [])\n",
    "        print(f\"Total files in {bucket_name}: {len(files)}\")\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading test files: {e}\")\n",
    "        return False\n",
    "\n",
    "# Create a test bucket and upload files\n",
    "bucket_name = \"ha-test-bucket\"\n",
    "if create_test_bucket(bucket_name):\n",
    "    upload_test_files(bucket_name, count=5, size_kb=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da11e2e4",
   "metadata": {},
   "source": [
    "## 6. Experiment 1: Master Server Failure\n",
    "\n",
    "Let's see what happens when a master server fails. We'll simulate this by stopping the leader master container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcfd324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_master_leader():\n",
    "    \"\"\"Find the current leader in the master cluster\"\"\"\n",
    "    leader = None\n",
    "    leader_id = None\n",
    "    \n",
    "    for i in range(1, 4):\n",
    "        try:\n",
    "            port = 9332 + i\n",
    "            response = requests.get(f\"http://localhost:{port}/cluster/status\", timeout=2)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                if \"Leader\" in data:\n",
    "                    leader = data[\"Leader\"]\n",
    "                    # Extract the leader ID (master1, master2, master3)\n",
    "                    if \"master1\" in leader:\n",
    "                        leader_id = \"master1\"\n",
    "                    elif \"master2\" in leader:\n",
    "                        leader_id = \"master2\"\n",
    "                    elif \"master3\" in leader:\n",
    "                        leader_id = \"master3\"\n",
    "                    break\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    return leader, leader_id\n",
    "\n",
    "# Find current leader\n",
    "leader, leader_id = find_master_leader()\n",
    "print(f\"Current master leader: {leader} (ID: {leader_id})\")\n",
    "\n",
    "if leader_id:\n",
    "    # Stop the leader container\n",
    "    print(f\"\\nSimulating leader failure by stopping {leader_id}...\")\n",
    "    stop_container(leader_id)\n",
    "    \n",
    "    # Wait for leader election\n",
    "    print(\"\\nWaiting for leader election...\")\n",
    "    time.sleep(15)\n",
    "    \n",
    "    # Check new leader\n",
    "    new_leader, new_leader_id = find_master_leader()\n",
    "    print(f\"\\nNew master leader: {new_leader} (ID: {new_leader_id})\")\n",
    "    \n",
    "    # Check cluster state\n",
    "    display_cluster_info()\n",
    "    \n",
    "    # Check S3 operations still work\n",
    "    print(\"\\nVerifying S3 operations...\")\n",
    "    try:\n",
    "        s3_client = create_s3_client()\n",
    "        response = s3_client.list_objects_v2(Bucket=bucket_name)\n",
    "        files = response.get('Contents', [])\n",
    "        print(f\"S3 operations working. Files in bucket: {len(files)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error with S3 operations: {e}\")\n",
    "        \n",
    "    # Restart the failed leader\n",
    "    print(f\"\\nRestarting failed leader {leader_id}...\")\n",
    "    start_container(leader_id)\n",
    "    \n",
    "    # Wait for it to rejoin\n",
    "    print(\"Waiting for leader to rejoin cluster...\")\n",
    "    time.sleep(15)\n",
    "    \n",
    "    # Final check\n",
    "    print(\"\\nFinal cluster state after leader recovery:\")\n",
    "    display_cluster_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b49ffa",
   "metadata": {},
   "source": [
    "## 7. Experiment 2: Volume Server Failure\n",
    "\n",
    "Now let's see what happens when a volume server fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188da07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check topology first to understand volume distribution\n",
    "topology = get_topology()\n",
    "\n",
    "# Extract volume information by server\n",
    "volumes_by_server = {}\n",
    "if \"error\" not in topology:\n",
    "    for dc in topology.get('DataCenters', []):\n",
    "        for rack in dc.get('Racks', []):\n",
    "            for datanode in rack.get('DataNodes', []):\n",
    "                server_id = datanode.get('Id', 'unknown')\n",
    "                volumes = datanode.get('Volumes', [])\n",
    "                volumes_by_server[server_id] = volumes\n",
    "\n",
    "# Display volume distribution\n",
    "print(\"Volume distribution before failure:\")\n",
    "for server, volumes in volumes_by_server.items():\n",
    "    print(f\"  {server}: {len(volumes)} volumes\")\n",
    "    for vol in volumes[:3]:  # Show first few volumes\n",
    "        print(f\"    - Volume {vol.get('Id')}, Size: {vol.get('Size')}\")\n",
    "    if len(volumes) > 3:\n",
    "        print(f\"    - ... and {len(volumes) - 3} more\")\n",
    "\n",
    "# Select volume server to fail (using volume1 for this test)\n",
    "server_to_fail = \"volume1\"\n",
    "print(f\"\\nSimulating volume server failure by stopping {server_to_fail}...\")\n",
    "stop_container(server_to_fail)\n",
    "\n",
    "# Wait for the system to detect failure\n",
    "print(\"\\nWaiting for system to detect failure...\")\n",
    "time.sleep(20)\n",
    "\n",
    "# Check topology after failure\n",
    "print(\"\\nVolume distribution after failure:\")\n",
    "topology = get_topology()\n",
    "volumes_by_server = {}\n",
    "if \"error\" not in topology:\n",
    "    for dc in topology.get('DataCenters', []):\n",
    "        for rack in dc.get('Racks', []):\n",
    "            for datanode in rack.get('DataNodes', []):\n",
    "                server_id = datanode.get('Id', 'unknown')\n",
    "                volumes = datanode.get('Volumes', [])\n",
    "                volumes_by_server[server_id] = volumes\n",
    "\n",
    "for server, volumes in volumes_by_server.items():\n",
    "    print(f\"  {server}: {len(volumes)} volumes\")\n",
    "\n",
    "# Check S3 operations still work\n",
    "print(\"\\nVerifying S3 operations...\")\n",
    "try:\n",
    "    s3_client = create_s3_client()\n",
    "    # Try to list files\n",
    "    response = s3_client.list_objects_v2(Bucket=bucket_name)\n",
    "    files = response.get('Contents', [])\n",
    "    print(f\"S3 list operation working. Files in bucket: {len(files)}\")\n",
    "    \n",
    "    # Try to download a file\n",
    "    if files:\n",
    "        key = files[0]['Key']\n",
    "        response = s3_client.get_object(Bucket=bucket_name, Key=key)\n",
    "        content_length = response['ContentLength']\n",
    "        print(f\"S3 download operation working. Downloaded {key} ({content_length} bytes)\")\n",
    "        \n",
    "    # Try to upload a new file\n",
    "    new_key = f\"test-recovery-{uuid.uuid4()}.dat\"\n",
    "    data = bytes(np.random.bytes(1024))\n",
    "    s3_client.put_object(Bucket=bucket_name, Key=new_key, Body=data)\n",
    "    print(f\"S3 upload operation working. Uploaded {new_key}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error with S3 operations: {e}\")\n",
    "\n",
    "# Restart the failed volume server\n",
    "print(f\"\\nRestarting failed volume server {server_to_fail}...\")\n",
    "start_container(server_to_fail)\n",
    "\n",
    "# Wait for recovery\n",
    "print(\"\\nWaiting for volume server to recover...\")\n",
    "time.sleep(20)\n",
    "\n",
    "# Check final topology\n",
    "print(\"\\nVolume distribution after recovery:\")\n",
    "topology = get_topology()\n",
    "volumes_by_server = {}\n",
    "if \"error\" not in topology:\n",
    "    for dc in topology.get('DataCenters', []):\n",
    "        for rack in dc.get('Racks', []):\n",
    "            for datanode in rack.get('DataNodes', []):\n",
    "                server_id = datanode.get('Id', 'unknown')\n",
    "                volumes = datanode.get('Volumes', [])\n",
    "                volumes_by_server[server_id] = volumes\n",
    "\n",
    "for server, volumes in volumes_by_server.items():\n",
    "    print(f\"  {server}: {len(volumes)} volumes\")\n",
    "    \n",
    "# Final check of cluster state\n",
    "print(\"\\nFinal cluster state after volume server recovery:\")\n",
    "display_cluster_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcde0b39",
   "metadata": {},
   "source": [
    "## 8. Experiment 3: Filer Service Failure and Load Balancing\n",
    "\n",
    "Let's test the resilience of the filer service using NGINX for load balancing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd26b3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, make a direct request to each filer to verify they're working\n",
    "print(\"Checking individual filer services:\")\n",
    "filer1_status = \"Unknown\"\n",
    "filer2_status = \"Unknown\"\n",
    "\n",
    "try:\n",
    "    response = requests.get(\"http://localhost:8888\", timeout=2)\n",
    "    filer1_status = f\"Working (status code: {response.status_code})\"\n",
    "except Exception as e:\n",
    "    filer1_status = f\"Error: {str(e)}\"\n",
    "\n",
    "try:\n",
    "    response = requests.get(\"http://localhost:8889\", timeout=2)\n",
    "    filer2_status = f\"Working (status code: {response.status_code})\"\n",
    "except Exception as e:\n",
    "    filer2_status = f\"Error: {str(e)}\"\n",
    "\n",
    "print(f\"  Filer1 (port 8888): {filer1_status}\")\n",
    "print(f\"  Filer2 (port 8889): {filer2_status}\")\n",
    "\n",
    "# Now test the load balanced endpoint\n",
    "print(\"\\nChecking NGINX load balanced endpoint:\")\n",
    "try:\n",
    "    response = requests.get(\"http://localhost:9080\", timeout=2)\n",
    "    print(f\"  NGINX (port 9080): Working (status code: {response.status_code})\")\n",
    "except Exception as e:\n",
    "    print(f\"  NGINX (port 9080): Error: {str(e)}\")\n",
    "\n",
    "# Test with S3 operations through NGINX\n",
    "print(\"\\nTesting S3 operations through NGINX:\")\n",
    "try:\n",
    "    s3_client = create_s3_client(use_nginx=True)\n",
    "    response = s3_client.list_objects_v2(Bucket=bucket_name)\n",
    "    files = response.get('Contents', [])\n",
    "    print(f\"  S3 operations via NGINX working. Files in bucket: {len(files)}\")\n",
    "except Exception as e:\n",
    "    print(f\"  Error with S3 operations via NGINX: {e}\")\n",
    "\n",
    "# Now simulate a failure of filer1\n",
    "print(\"\\nSimulating filer1 failure...\")\n",
    "stop_container(\"filer1\")\n",
    "print(\"Waiting for NGINX to detect failure...\")\n",
    "time.sleep(10)\n",
    "\n",
    "# Test direct access to filer1 (should fail)\n",
    "try:\n",
    "    response = requests.get(\"http://localhost:8888\", timeout=2)\n",
    "    print(f\"  Filer1 (port 8888): Still accessible (status code: {response.status_code})\")\n",
    "except Exception as e:\n",
    "    print(f\"  Filer1 (port 8888): Confirmed down: {str(e)}\")\n",
    "\n",
    "# Test load balanced endpoint (should switch to filer2)\n",
    "print(\"\\nTesting load balanced endpoint after filer1 failure:\")\n",
    "try:\n",
    "    response = requests.get(\"http://localhost:9080\", timeout=2)\n",
    "    print(f\"  NGINX (port 9080): Working (status code: {response.status_code})\")\n",
    "except Exception as e:\n",
    "    print(f\"  NGINX (port 9080): Error: {str(e)}\")\n",
    "\n",
    "# Test S3 operations again\n",
    "print(\"\\nTesting S3 operations after filer1 failure:\")\n",
    "try:\n",
    "    s3_client = create_s3_client(use_nginx=True)\n",
    "    response = s3_client.list_objects_v2(Bucket=bucket_name)\n",
    "    files = response.get('Contents', [])\n",
    "    print(f\"  S3 operations via NGINX working. Files in bucket: {len(files)}\")\n",
    "    \n",
    "    # Upload a new file to verify write operations\n",
    "    new_key = f\"test-failover-{uuid.uuid4()}.dat\"\n",
    "    data = bytes(np.random.bytes(1024))\n",
    "    s3_client.put_object(Bucket=bucket_name, Key=new_key, Body=data)\n",
    "    print(f\"  S3 upload operation working. Uploaded {new_key}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"  Error with S3 operations via NGINX: {e}\")\n",
    "\n",
    "# Restore filer1\n",
    "print(\"\\nRestarting filer1...\")\n",
    "start_container(\"filer1\")\n",
    "print(\"Waiting for filer1 to recover...\")\n",
    "time.sleep(20)\n",
    "\n",
    "# Final check\n",
    "print(\"\\nFinal state after filer1 recovery:\")\n",
    "try:\n",
    "    response = requests.get(\"http://localhost:8888\", timeout=2)\n",
    "    print(f\"  Filer1 (port 8888): Recovered (status code: {response.status_code})\")\n",
    "except Exception as e:\n",
    "    print(f\"  Filer1 (port 8888): Still down: {str(e)}\")\n",
    "\n",
    "# Test S3 operations again\n",
    "print(\"\\nVerifying S3 operations after recovery:\")\n",
    "try:\n",
    "    s3_client = create_s3_client(use_nginx=True)\n",
    "    response = s3_client.list_objects_v2(Bucket=bucket_name)\n",
    "    files = response.get('Contents', [])\n",
    "    print(f\"  S3 operations working. Files in bucket: {len(files)}\")\n",
    "except Exception as e:\n",
    "    print(f\"  Error with S3 operations: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad1d0af",
   "metadata": {},
   "source": [
    "## 9. Data Integrity Verification\n",
    "\n",
    "Let's verify that our data remains intact after all these failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d0f734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_file(size_kb=100):\n",
    "    \"\"\"Create a test file with predictable content\"\"\"\n",
    "    # Create deterministic content\n",
    "    content = bytes([i % 256 for i in range(size_kb * 1024)])\n",
    "    return content\n",
    "\n",
    "def verify_file_content(bucket, key, original_content):\n",
    "    \"\"\"Verify file content matches original\"\"\"\n",
    "    try:\n",
    "        s3_client = create_s3_client()\n",
    "        response = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "        retrieved_content = response['Body'].read()\n",
    "        \n",
    "        # Check if content matches\n",
    "        if retrieved_content == original_content:\n",
    "            return True, None\n",
    "        else:\n",
    "            # If sizes differ, report that\n",
    "            if len(retrieved_content) != len(original_content):\n",
    "                return False, f\"Size mismatch: expected {len(original_content)} bytes, got {len(retrieved_content)} bytes\"\n",
    "            \n",
    "            # Otherwise, find where they differ\n",
    "            for i in range(len(original_content)):\n",
    "                if original_content[i] != retrieved_content[i]:\n",
    "                    return False, f\"Content differs at byte {i}: expected {original_content[i]}, got {retrieved_content[i]}\"\n",
    "            \n",
    "            return False, \"Unknown content mismatch\"\n",
    "    except Exception as e:\n",
    "        return False, str(e)\n",
    "\n",
    "# Create a unique test file\n",
    "test_content = create_test_file(size_kb=100)\n",
    "test_key = f\"integrity-test-{uuid.uuid4()}.dat\"\n",
    "\n",
    "print(f\"Creating integrity test file '{test_key}' ({len(test_content)} bytes)\")\n",
    "try:\n",
    "    s3_client = create_s3_client()\n",
    "    s3_client.put_object(Bucket=bucket_name, Key=test_key, Body=test_content)\n",
    "    print(\"  File uploaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"  Error uploading test file: {e}\")\n",
    "\n",
    "# Verify file integrity\n",
    "print(\"\\nVerifying file integrity...\")\n",
    "is_intact, error = verify_file_content(bucket_name, test_key, test_content)\n",
    "if is_intact:\n",
    "    print(\"  File integrity verified: Content matches exactly\")\n",
    "else:\n",
    "    print(f\"  File integrity check failed: {error}\")\n",
    "\n",
    "# Now we'll trigger multiple component failures at once to test extreme resilience\n",
    "print(\"\\nSimulating multiple component failures simultaneously...\")\n",
    "stop_container(\"volume1\")\n",
    "stop_container(\"filer1\")\n",
    "\n",
    "# If we have a leader ID from earlier, fail that as well\n",
    "current_leader, current_leader_id = find_master_leader()\n",
    "if current_leader_id:\n",
    "    stop_container(current_leader_id)\n",
    "    print(f\"Stopped master leader {current_leader_id}\")\n",
    "\n",
    "print(\"Waiting for system to stabilize after multiple failures...\")\n",
    "time.sleep(30)\n",
    "\n",
    "# Check system status\n",
    "print(\"\\nSystem status after multiple failures:\")\n",
    "display_cluster_info()\n",
    "\n",
    "# Verify data integrity again\n",
    "print(\"\\nVerifying file integrity after multiple failures...\")\n",
    "is_intact, error = verify_file_content(bucket_name, test_key, test_content)\n",
    "if is_intact:\n",
    "    print(\"  File integrity verified: Content matches exactly\")\n",
    "else:\n",
    "    print(f\"  File integrity check failed: {error}\")\n",
    "\n",
    "# Restore all containers\n",
    "print(\"\\nRestoring all failed containers...\")\n",
    "start_container(\"volume1\")\n",
    "start_container(\"filer1\")\n",
    "if current_leader_id:\n",
    "    start_container(current_leader_id)\n",
    "\n",
    "print(\"\\nWaiting for system to fully recover...\")\n",
    "time.sleep(30)\n",
    "\n",
    "# Final integrity check\n",
    "print(\"\\nFinal integrity verification:\")\n",
    "is_intact, error = verify_file_content(bucket_name, test_key, test_content)\n",
    "if is_intact:\n",
    "    print(\"  File integrity verified: Content matches exactly\")\n",
    "else:\n",
    "    print(f\"  File integrity check failed: {error}\")\n",
    "\n",
    "# Check final system status\n",
    "print(\"\\nFinal system status:\")\n",
    "display_cluster_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd860362",
   "metadata": {},
   "source": [
    "## 10. Conclusions\n",
    "\n",
    "Based on our experiments with SeaweedFS high availability configuration, we can draw the following conclusions:\n",
    "\n",
    "1. **Master Server Resilience**: The Raft-based master cluster provides excellent fault tolerance. When the leader fails, another master quickly takes over leadership role, ensuring uninterrupted service.\n",
    "\n",
    "2. **Volume Server Redundancy**: With multiple volume servers across different racks, data remains accessible even when a volume server fails. The system can continue to serve both read and write operations.\n",
    "\n",
    "3. **Filer Service High Availability**: Using NGINX as a load balancer in front of multiple filer instances ensures continuous service even when one filer becomes unavailable.\n",
    "\n",
    "4. **Data Integrity**: Our tests show that data remains intact and consistent even after multiple component failures, demonstrating SeaweedFS's strong data consistency guarantees.\n",
    "\n",
    "5. **Recovery Process**: When failed components are restored, they seamlessly rejoin the cluster and resume their functions without manual intervention.\n",
    "\n",
    "These findings confirm that SeaweedFS, when properly configured for high availability as in our setup, provides robust resilience against various types of failures, making it suitable for production environments where high availability is critical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccf93d9",
   "metadata": {},
   "source": [
    "## 11. System Monitoring Dashboard\n",
    "\n",
    "Let's create a simple monitoring dashboard to observe the system health over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aebdff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_system_metrics():\n",
    "    \"\"\"Collect key metrics from the SeaweedFS system\"\"\"\n",
    "    metrics = {\n",
    "        'timestamp': time.time(),\n",
    "        'masters_up': 0,\n",
    "        'volumes_up': 0,\n",
    "        'filers_up': 0,\n",
    "        'total_volumes': 0,\n",
    "        'leader_id': None,\n",
    "        's3_api_status': False\n",
    "    }\n",
    "    \n",
    "    # Check masters\n",
    "    for i in range(1, 4):\n",
    "        try:\n",
    "            port = 9332 + i\n",
    "            response = requests.get(f\"http://localhost:{port}/cluster/status\", timeout=1)\n",
    "            if response.status_code == 200:\n",
    "                metrics['masters_up'] += 1\n",
    "                data = response.json()\n",
    "                if \"Leader\" in data:\n",
    "                    if \"master1\" in data[\"Leader\"]:\n",
    "                        metrics['leader_id'] = \"master1\"\n",
    "                    elif \"master2\" in data[\"Leader\"]:\n",
    "                        metrics['leader_id'] = \"master2\"\n",
    "                    elif \"master3\" in data[\"Leader\"]:\n",
    "                        metrics['leader_id'] = \"master3\"\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Check volumes\n",
    "    for i in range(1, 4):\n",
    "        try:\n",
    "            port = 8079 + i\n",
    "            response = requests.get(f\"http://localhost:{port}/status\", timeout=1)\n",
    "            if response.status_code == 200:\n",
    "                metrics['volumes_up'] += 1\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Check filers\n",
    "    try:\n",
    "        response = requests.get(\"http://localhost:8888\", timeout=1)\n",
    "        if response.status_code == 200:\n",
    "            metrics['filers_up'] += 1\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    try:\n",
    "        response = requests.get(\"http://localhost:8889\", timeout=1)\n",
    "        if response.status_code == 200:\n",
    "            metrics['filers_up'] += 1\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Check topology for volume count\n",
    "    topology = get_topology()\n",
    "    if \"error\" not in topology:\n",
    "        volume_count = 0\n",
    "        for dc in topology.get('DataCenters', []):\n",
    "            for rack in dc.get('Racks', []):\n",
    "                for datanode in rack.get('DataNodes', []):\n",
    "                    volume_count += len(datanode.get('Volumes', []))\n",
    "        metrics['total_volumes'] = volume_count\n",
    "    \n",
    "    # Check S3 API\n",
    "    try:\n",
    "        s3_client = create_s3_client()\n",
    "        s3_client.list_buckets()\n",
    "        metrics['s3_api_status'] = True\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def run_monitoring(duration=60, interval=5):\n",
    "    \"\"\"Run monitoring for a specified duration\"\"\"\n",
    "    print(f\"Starting system monitoring for {duration} seconds...\")\n",
    "    metrics_history = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    end_time = start_time + duration\n",
    "    \n",
    "    try:\n",
    "        while time.time() < end_time:\n",
    "            metrics = collect_system_metrics()\n",
    "            metrics_history.append(metrics)\n",
    "            \n",
    "            # Calculate elapsed time\n",
    "            elapsed = time.time() - start_time\n",
    "            remaining = max(0, duration - elapsed)\n",
    "            \n",
    "            # Clear output and show current metrics\n",
    "            clear_output(wait=True)\n",
    "            print(f\"System Monitoring - {remaining:.1f} seconds remaining\")\n",
    "            print(f\"Masters online: {metrics['masters_up']}/3 (Leader: {metrics['leader_id'] or 'Unknown'})\")\n",
    "            print(f\"Volume servers online: {metrics['volumes_up']}/3\")\n",
    "            print(f\"Filer servers online: {metrics['filers_up']}/2\")\n",
    "            print(f\"Total volumes: {metrics['total_volumes']}\")\n",
    "            print(f\"S3 API status: {'Working' if metrics['s3_api_status'] else 'Down'}\")\n",
    "            \n",
    "            # Create basic chart if we have enough data points\n",
    "            if len(metrics_history) > 1:\n",
    "                timestamps = [(m['timestamp'] - start_time) for m in metrics_history]\n",
    "                masters = [m['masters_up'] for m in metrics_history]\n",
    "                volumes = [m['volumes_up'] for m in metrics_history]\n",
    "                filers = [m['filers_up'] for m in metrics_history]\n",
    "                s3_status = [1 if m['s3_api_status'] else 0 for m in metrics_history]\n",
    "                \n",
    "                plt.figure(figsize=(10, 6))\n",
    "                plt.plot(timestamps, masters, 'b-', label='Masters')\n",
    "                plt.plot(timestamps, volumes, 'g-', label='Volumes')\n",
    "                plt.plot(timestamps, filers, 'r-', label='Filers')\n",
    "                plt.plot(timestamps, s3_status, 'k--', label='S3 API')\n",
    "                plt.xlabel('Time (seconds)')\n",
    "                plt.ylabel('Count')\n",
    "                plt.title('SeaweedFS System Health')\n",
    "                plt.legend()\n",
    "                plt.grid(True)\n",
    "                plt.ylim(-0.1, 3.1)  # Set y-axis limits\n",
    "                plt.show()\n",
    "            \n",
    "            # Wait for next interval\n",
    "            time.sleep(interval)\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Monitoring stopped by user\")\n",
    "    \n",
    "    return metrics_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f25702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run monitoring for 60 seconds, with metrics collected every 5 seconds\n",
    "metrics_history = run_monitoring(duration=60, interval=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff8f914",
   "metadata": {},
   "source": [
    "## 12. Cleanup\n",
    "\n",
    "If you want to clean up the resources created during this experiment, you can run the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce23aca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_test_data():\n",
    "    \"\"\"Clean up the test bucket and files\"\"\"\n",
    "    print(\"Cleaning up test data...\")\n",
    "    try:\n",
    "        s3_client = create_s3_client()\n",
    "        \n",
    "        # List all objects in the bucket\n",
    "        response = s3_client.list_objects_v2(Bucket=bucket_name)\n",
    "        if 'Contents' in response:\n",
    "            # Delete each object\n",
    "            for obj in response['Contents']:\n",
    "                s3_client.delete_object(Bucket=bucket_name, Key=obj['Key'])\n",
    "                print(f\"Deleted {obj['Key']}\")\n",
    "        \n",
    "        # Delete the bucket\n",
    "        s3_client.delete_bucket(Bucket=bucket_name)\n",
    "        print(f\"Deleted bucket {bucket_name}\")\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error during cleanup: {e}\")\n",
    "        return False\n",
    "\n",
    "# Uncomment the following line if you want to clean up test data\n",
    "# cleanup_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b15e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following line if you want to stop the HA cluster\n",
    "# stop_ha_cluster()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6790c350",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we explored the Active-Active resilience capabilities of SeaweedFS using a high-availability setup with multiple masters, volume servers, and filers. Our experiments demonstrated:\n",
    "\n",
    "1. **Fault Tolerance**: The system continues to operate even when critical components fail, including master leaders, volume servers, and filer servers.\n",
    "\n",
    "2. **Self-Healing**: When failed components are restored, they automatically rejoin the cluster and resume their functions.\n",
    "\n",
    "3. **Data Integrity**: Data remains accessible and consistent throughout component failures and recoveries.\n",
    "\n",
    "4. **Load Balancing**: Using NGINX as a load balancer ensures continuous service even when individual components are unavailable.\n",
    "\n",
    "5. **Secure Network Architecture**: By isolating components to the internal network and exposing only NGINX to the external network, we've implemented a secure architecture that minimizes the attack surface.\n",
    "\n",
    "6. **Path-Based Routing**: All SeaweedFS components (masters, volumes, filers) are accessible through a single entry point using path-based routing in NGINX, simplifying access management while maintaining security.\n",
    "\n",
    "This resilient architecture makes SeaweedFS suitable for mission-critical applications where high availability, data durability, and security are essential requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d242bd2d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eaf9e9e1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcd577cc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
