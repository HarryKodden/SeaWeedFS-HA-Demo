# Define base image of seaweedfs
x-seaweedfs: &seaweedfs
  image: chrislusf/seaweedfs:latest
  restart: unless-stopped
  networks:
    - internal

# Define base configurations using YAML anchors
x-master-base: &master-base
  <<: *seaweedfs
  volumes:
    - /data
  healthcheck: &master-healthcheck
    test: ["CMD", "wget", "--spider", "-q", "http://localhost:9333/cluster/status"]
    interval: 10s
    timeout: 5s
    retries: 3
    start_period: 10s

x-volume-base: &volume-base
  <<: *seaweedfs
  depends_on:
    master1:
      condition: service_healthy
  volumes:
    - /data
  healthcheck: &volume-healthcheck
    test: ["CMD", "wget", "--spider", "-q", "http://localhost:8080/status"]
    interval: 10s
    timeout: 5s
    retries: 3
    start_period: 10s

x-filer-base: &filer-base
  <<: *seaweedfs
  depends_on:
    master1:
      condition: service_healthy
    volume1:
      condition: service_healthy
  environment:
    AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
    AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
  deploy:
    resources:
      limits:
        cpus: '1'
        memory: 1G
  volumes:
    - /data
  healthcheck: &filer-healthcheck
    test: ["CMD", "wget", "--spider", "-q", "http://localhost:8888/"]
    interval: 10s
    timeout: 5s
    retries: 3
    start_period: 15s

services:
  # Master servers using base configuration
  master1:
    <<: *master-base
    container_name: master1
    command: "master -port=9333 -ip=master1 -mdir=/data -peers=master1:9333,master2:9333,master3:9333"
    volumes:
      - master1_data:/data
    healthcheck:
      <<: *master-healthcheck
      test: ["CMD", "wget", "--spider", "-q", "http://master1:9333/cluster/status"]

  master2:
    <<: *master-base
    container_name: master2
    command: "master -port=9333 -ip=master2 -mdir=/data -peers=master1:9333,master2:9333,master3:9333"
    volumes:
      - master2_data:/data
    healthcheck:
      <<: *master-healthcheck
      test: ["CMD", "wget", "--spider", "-q", "http://master2:9333/cluster/status"]

  master3:
    <<: *master-base
    container_name: master3
    command: "master -port=9333 -ip=master3 -mdir=/data -peers=master1:9333,master2:9333,master3:9333"
    volumes:
      - master3_data:/data
    healthcheck:
      <<: *master-healthcheck
      test: ["CMD", "wget", "--spider", "-q", "http://master3:9333/cluster/status"]

  # Volume servers using base configuration
  volume1:
    <<: *volume-base
    container_name: volume1
    command: "volume -port=8080 -ip=volume1 -mserver=master1:9333,master2:9333,master3:9333 -dir=/data -max=5 -rack=rack1"
    volumes:
      - volume1_data:/data
    healthcheck:
      <<: *volume-healthcheck
      test: ["CMD", "wget", "--spider", "-q", "http://volume1:8080/status"]

  volume2:
    <<: *volume-base
    container_name: volume2
    command: "volume -port=8080 -ip=volume2 -mserver=master1:9333,master2:9333,master3:9333 -dir=/data -max=5 -rack=rack2"
    volumes:
      - volume2_data:/data
    healthcheck:
      <<: *volume-healthcheck
      test: ["CMD", "wget", "--spider", "-q", "http://volume2:8080/status"]

  volume3:
    <<: *volume-base
    container_name: volume3
    command: "volume -port=8080 -ip=volume3 -mserver=master1:9333,master2:9333,master3:9333 -dir=/data -max=5 -rack=rack3"
    volumes:
      - volume3_data:/data
    healthcheck:
      <<: *volume-healthcheck
      test: ["CMD", "wget", "--spider", "-q", "http://volume3:8080/status"]

  # Filer servers using base configuration
  filer1:
    <<: *filer-base
    container_name: filer1
    volumes:
      - filer1_data:/data
    command: "filer -master=master1:9333,master2:9333,master3:9333 -ip=filer1 -port=8888 -port.grpc=18888 -s3 -s3.port=8333 -s3.allowEmptyFolder=true -dataCenter=dc1 -maxMB=1024"
    healthcheck:
      <<: *filer-healthcheck
      test: ["CMD", "wget", "--spider", "-q", "http://filer1:8888/"]

  filer2:
    <<: *filer-base
    container_name: filer2
    volumes:
      - filer2_data:/data
    command: "filer -master=master1:9333,master2:9333,master3:9333 -ip=filer2 -port=8888 -port.grpc=18888 -s3 -s3.port=8333 -s3.allowEmptyFolder=true -dataCenter=dc1 -maxMB=1024"
    healthcheck:
      <<: *filer-healthcheck
      test: ["CMD", "wget", "--spider", "-q", "http://filer2:8888/"]

  # API server (no changes needed)
  api:
    build:
      context: api
      args:
        DOCKER_GID: ${DOCKER_GID}
    container_name: api
    environment:
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      SEAWEED_S3_URL: ${SEAWEED_S3_URL}
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - internal
    healthcheck:
      test: ["CMD", "curl", "-f", "http://api:8080/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # Proxy server (no changes needed)
  proxy:
    build: proxy
    container_name: proxy
    ports:
      - "80:80"
      - "8080:8080"
      - "8333:8333"
    volumes:
      - ./.htpasswd:/etc/nginx/.htpasswd
    networks:
      - internal
      - external
    depends_on:
      filer1:
        condition: service_healthy
      filer2:
        condition: service_healthy
      master1:
        condition: service_healthy
      master2:
        condition: service_healthy
      master3:
        condition: service_healthy
      volume1:
        condition: service_healthy
      volume2:
        condition: service_healthy
      volume3:
        condition: service_healthy
      api:
        condition: service_healthy

networks:
  external:
    name: external
  internal:
    name: internal

volumes:
  master1_data:
  master2_data:
  master3_data:
  volume1_data:
  volume2_data:
  volume3_data:
  filer1_data:
  filer2_data:
